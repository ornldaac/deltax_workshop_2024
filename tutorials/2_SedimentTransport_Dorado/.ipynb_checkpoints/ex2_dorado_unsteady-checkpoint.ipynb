{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e72087d-685e-4b67-9856-e709d8140a23",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/soloyant/deltax_workshop_2024/blob/main/tutorials/2_SedimentTransport_Dorado/ex2_dorado_unsteady.ipynb)\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"notebook_illustrations/deltax_2020.png\" alt=\"Delta-X Logo\" style=\"height: 100px; width: auto; display: inline;\">\n",
    "    <img src=\"notebook_illustrations/Tribrand_ColorBlack_rgb_16x3_160601.png\" alt=\"JPL Logo\" style=\"height: 100px; width: auto; display: inline;\">\n",
    "</div>\n",
    "<h1 style=\"text-align: center;\">Delta-X 2024 Application Workshop - May 8, 2024</h1>\n",
    "<h2 style=\"text-align: center;\">Dorado Lagrangian Transport: Hands On Exercises</h2>\n",
    "<h2 style=\"text-align: center;\">Part 2/2: Unsteady Case</h2>\n",
    "\n",
    "<h3>Authors information:</h3>\n",
    "\n",
    "**Muriel Z.M. Brückner, Ph.D.**  \n",
    "Assistant Professor  \n",
    "Coastal Engineering  \n",
    "Department of Civil and Environmental Engineering  \n",
    "College of Engineering  \n",
    "Louisiana State University  \n",
    "\n",
    "**Antoine Soloy, Ph.D.**  \n",
    "Division 334F, Caltech - Jet Propulsion Laboratory  \n",
    "4800 Oak Grove Drive, Pasadena, CA, USA  91109-8099  \n",
    "Contact: antoine.soloy@jpl.nasa.gov\n",
    "\n",
    "# *dorado* Example 2 - unsteady simulation with unstructured grid\n",
    "\n",
    "In this example, we will be routing our particles in an unsteady flow field derived from our previous ANUGA simulation. If you were unable to finish the previous exercise, the results data can be found in the parent directory under model_outputs.\n",
    "\n",
    "**Note: the below code sets the directory relative to where this script is stored. Make sure that you set the different directories relative to where your data is stored.**\n",
    "\n",
    "First, we import the required packages and set our directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06eaba72-7be5-484e-937e-f84089fc0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  # In case the notebook is opened in google collab, here we download/install all the files we need behind the scenes\n",
    "  try:\n",
    "      import os\n",
    "      os.chdir('/content')\n",
    "      # Grab workbook files into colab directory\n",
    "      !git clone https://github.com/soloyant/deltax_workshop_2024.git\n",
    "      !pip install git+https://github.com/passaH2O/dorado.git\n",
    "      !pip install git+https://github.com/GeoscienceAustralia/anuga_core.git\n",
    "      !pip install dill gitpython meshpy netcdf4 Pmw pymetis utm rasterio\n",
    "      os.chdir('/content/deltax_workshop_2024/tutorials/2_SedimentTransport_Dorado/')\n",
    "  except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec388147-1ed5-4887-9d39-4190f492ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import dorado\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from anuga import utilities\n",
    "import dorado.particle_track as pt\n",
    "import dorado.routines as drt\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.path import Path\n",
    "from utils import dorado_visualization_tools as dorado_dvt\n",
    "\n",
    "# get working directory (where the script is located)\n",
    "par_dir = os.getcwd()\n",
    "workshop_dir = os.path.abspath(os.path.join(par_dir,\"..\"))\n",
    "\n",
    "# define here the directory where your anuga files are saved\n",
    "model_data = os.path.join(workshop_dir, '1_HydrodynamicModeling_ANUGA/data/collab')\n",
    "\n",
    "# define the name of your sww-file generated by ANUGA\n",
    "swwname = '20210327000000_DX_Workshop_1_days.sww'\n",
    "\n",
    "# this is the path to where the sww-file is stored \n",
    "anuga_out_dir = os.path.join(workshop_dir, '1_HydrodynamicModeling_ANUGA/model_outputs/collab')\n",
    "\n",
    "# Create a subfolder to save the output data:\n",
    "subfolder = 'Nourishment_analysis_unsteady'\n",
    "try:\n",
    "    os.makedirs(os.path.join(par_dir, subfolder))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Import tools from the anuga segment of the workshop\n",
    "import sys\n",
    "# Define here the path that leads to the utils folder in ANUGA\n",
    "anuga_utils_dir = os.path.join(workshop_dir, '1_HydrodynamicModeling_ANUGA/utils')\n",
    "sys.path.append(anuga_utils_dir)\n",
    "\n",
    "# from utils import data_plots as dpt\n",
    "import data_processing_tools as anuga_dpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98cddb-9b09-4f98-be21-0c60ea11dfd3",
   "metadata": {},
   "source": [
    "### Define scenarios\n",
    "\n",
    "Here we can define the theta used in the model. You can rerun the script by adjust the theta to inspect where the particles are going for the different scenarios. We create a subfolder here to save the dorado output for each theta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b626d9-46ed-4e55-97b0-0dd336f127d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your output folder path: /Users/soloy/Documents/GitHub/deltax_workshop_2024/tutorials/2_SedimentTransport_Dorado/Nourishment_analysis_unsteady/Nourish_t1.0\n"
     ]
    }
   ],
   "source": [
    "theta = 1.0\n",
    "\n",
    "outname = 'Nourish_t%s' % (theta)\n",
    "\n",
    "mydir = os.path.join(par_dir, subfolder,outname)\n",
    "try:\n",
    "    os.makedirs(mydir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('This is your output folder path:', mydir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7ab63-2893-47db-92e5-f902f04aa891",
   "metadata": {},
   "source": [
    "### Load Model Outputs\n",
    "\n",
    "First, we import the domain generated during the DEM processing step to clip our model results to the area that we are intested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9bb2cdb-81bb-4b12-a79f-251e5ab8b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_domain = os.path.join(model_data, 'dxws_domain.shp')\n",
    "domain_gdf = gpd.read_file(f_domain)\n",
    "# transform into list to be used in dorado functions\n",
    "domainPolygon = np.asarray(domain_gdf.geometry[0].boundary.xy).T.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd5ec8-e5a7-4da3-984f-c8510429f0da",
   "metadata": {},
   "source": [
    "Now we will read the output data from ANUGA and inpsect and extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc159a06-317e-4234-ace4-912430dcb05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the data structure of the ANUGA output file: <class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_64BIT_OFFSET data model, file format NETCDF3):\n",
      "    institution: Geosciences Australia\n",
      "    description: Output from anuga.file.sww suitable for plotting\n",
      "    smoothing: Yes\n",
      "    vertices_are_stored_uniquely: False\n",
      "    order: 2\n",
      "    revision_number: No git sha available\n",
      "    revision_date: No git date available\n",
      "    anuga_version: 3.0\n",
      "    starttime: 0.0\n",
      "    xllcorner: 651107.0144164033\n",
      "    yllcorner: 3247255.312158878\n",
      "    zone: -1\n",
      "    false_easting: 500000\n",
      "    false_northing: 10000000\n",
      "    datum: wgs84\n",
      "    projection: UTM\n",
      "    units: m\n",
      "    dimensions(sizes): number_of_volumes(18845), number_of_triangle_vertices(9587), number_of_vertices(3), numbers_in_range(2), number_of_points(9587), number_of_timesteps(25)\n",
      "    variables(dimensions): float32 x(number_of_points), float32 y(number_of_points), int32 volumes(number_of_volumes, number_of_vertices), float32 elevation(number_of_points), float32 elevation_range(numbers_in_range), float32 friction(number_of_points), float32 friction_range(numbers_in_range), float32 elevation_c(number_of_volumes), float32 friction_c(number_of_volumes), float32 stage(number_of_timesteps, number_of_points), float32 stage_range(numbers_in_range), float32 xmomentum(number_of_timesteps, number_of_points), float32 xmomentum_range(numbers_in_range), float32 ymomentum(number_of_timesteps, number_of_points), float32 ymomentum_range(numbers_in_range), float32 stage_c(number_of_timesteps, number_of_volumes), float32 xmomentum_c(number_of_timesteps, number_of_volumes), float32 ymomentum_c(number_of_timesteps, number_of_volumes), float64 time(number_of_timesteps)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "# read the netcdf-file (.sww) created in the ANUGA simulation\n",
    "data = Dataset(os.path.join(anuga_out_dir, swwname))\n",
    "print('This is the data structure of the ANUGA output file:', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fdec336-6a06-4770-903b-ad938b423d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the lower left corner coordinates to correct for the volume coordinates\n",
    "x_min = data.xllcorner\n",
    "y_min = data.yllcorner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f9962-547a-444a-91c1-1fa4e583da5f",
   "metadata": {},
   "source": [
    "Take your time to inspect the structure of the dataset. Which are the necessary data to run dorado?\n",
    "\n",
    "\n",
    "\n",
    "Now we need to interpolate the data from our ANUGA grid onto the dorado (rectangular) grid of a grid cell size of our choice. Here, we use an function *anuga.utilities.plot_utils.get_centroids()* that extracts the model quantities at the cell centers. If we used the above Dataset()-function, we would need to triangulate the coordinates from the triangular grid to the rectangular grid first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65a0f37-7be4-4f4d-9a4c-ead905049f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "swwvals = utilities.plot_utils.get_centroids(os.path.join(anuga_out_dir,swwname), timeSlices = 'all')\n",
    "# Query values: time, x, y, stage, elev, height, xmom, ymom, xvel, yvel, friction, vel, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45dc417-4c1f-48bd-8ca8-8132a2877933",
   "metadata": {},
   "source": [
    "We extract the time array from our simulation and combine our coordinates into a list of tuples. This is the expected format for coordinates in the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25216ae3-038e-4174-a40d-f8f02b420aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the time and coordinates of the grid saved as distance from the lower left corner.\n",
    "time = swwvals.time\n",
    "x = swwvals.x + x_min\n",
    "y = swwvals.y + y_min\n",
    "\n",
    "# Finally we make a list with the cell points called 'coordinates'\n",
    "coordinates = [(x[i], y[i]) for i in list(range(len(x)))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c61000-b30f-4125-a970-81a475389454",
   "metadata": {},
   "source": [
    "#### Grid interpolation for *dorado*\n",
    "Now that we have the data we need, we can convert it into the format needed by dorado. This will include gridding the hydrodynamic outputs and transforming our geospatial coordinates into “array index” coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a72b39-e15a-4cf0-b06c-c64ffb84bda9",
   "metadata": {},
   "source": [
    "Choose a grid cell size for your new mesh. You can play with this number to see how the interpolation changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5444bd-5b69-4ba3-911e-06b5b0ea866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 25 # meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63156637-830c-4e68-b5f3-b3d006a27715",
   "metadata": {},
   "source": [
    "Now we interpolate the data onto the new rectangluar grid by using the particle.track functionality *'unstruct2grid()'*,  which uses inverse-distance-weighted interpolation to create a Cartesian grid the same size as our model’s extent. To use this function, we need to provide: \n",
    "- a list of coordinates (as tuples)\n",
    "- The unstructured data we want to be gridded (here we start with elevation)\n",
    "- The desired grid size of the resulting rasters\n",
    "- The number of nearest neighbors *k* to use in the interpolation. If *k=1*, we use only the nearest datapoint, whereas higher values (default is *k=3*) interpolate the data into a smoother result.\n",
    "\n",
    "*'unstruct2grid()'* returns a gridded array of our data and a nearest-neighbor interpolation function for gridding additional             quantities *'myInterp'*.\n",
    "\n",
    "The resulting interpolation function myInterp (after building the nearest-distance tree), which will be considerably faster than calling unstruct2grid again if we are gridding additional datasets. This function assumes data have the same coordinates, grid size, and *k*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd5a33e-f496-4345-8686-e5551e9c22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(775, 838)\n"
     ]
    }
   ],
   "source": [
    "# extract the bed elevations\n",
    "elev = swwvals.elev\n",
    "\n",
    "# Use IDW interpolation interpolate unstructured data into uniform grid\n",
    "myInterp, bathy = pt.unstruct2grid(coordinates, elev , grid_size, 3,boundary=domainPolygon, crop=True)\n",
    "print(np.shape(bathy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f7526-cc29-4d69-90b8-a09efcc41daf",
   "metadata": {},
   "source": [
    "Here we extract the other needed variables for our dorado simulation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbda60cc-0f52-4f4f-85b4-29d7a8424ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# water depth\n",
    "depth = swwvals.height\n",
    "\n",
    "# water level\n",
    "stage = swwvals.stage\n",
    "\n",
    "# discharge x-direction\n",
    "qx = swwvals.xmom\n",
    "\n",
    "# discharge y-direction\n",
    "qy = swwvals.ymom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adf3cf-9225-4a66-be3b-ad9f1a459a46",
   "metadata": {},
   "source": [
    "#### Define seeding locations\n",
    "\n",
    "Next we need to define a seeding locations for our particles. If you’re modeling a real domain, it may be easier to figure out a good release location by opening some GIS software and finding the coordinates of that location. \n",
    "\n",
    "Here, we use the discharge boundary as our seeding location. To do this, we first need to load the discharge transect from the ANUGA tutorial and transform them into a list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e6ac21-9eb4-4ce9-9c77-68b960a7412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[667279.313355803, 3266508.6850163136], [668560.0948551947, 3266560.9169023586]]\n"
     ]
    }
   ],
   "source": [
    "# set the path to our file\n",
    "f_seeding_points = os.path.join(model_data, 'discharge_transect.shp')\n",
    "\n",
    "# import the file using the gdp package\n",
    "seeding_points_gdf = gpd.read_file(f_seeding_points)\n",
    "\n",
    "# transform our shape-file into a list\n",
    "seeding_points_loc = np.asarray(seeding_points_gdf.geometry[0].xy).T.tolist()\n",
    "\n",
    "# print the locations to inspect\n",
    "print(seeding_points_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b0e48-d88e-4dd6-9219-4d259f68abd6",
   "metadata": {},
   "source": [
    "Check if the coordinates make sense. \n",
    "\n",
    "Next, we need to transform the coordinates into the indices on our rectangular grid using the function *particle_track.coord2ind()* to convert your coordinates into array indices. \n",
    "This function requires: \n",
    "- Coordinates to be converted, as a list [] of tuples\n",
    "- The location of the lower left corner of your rasters (i.e. the origin). If you used unstruct2grid to generate rasters, this location will be [(min(x), min(y))]. Otherwise, if you’re loading data from e.g. a GeoTIFF, the lower left corner will be stored in the .tif metadata and can be accessed by GIS software or gdalinfo from the GDAL package.\n",
    "\n",
    "We assume in all of these functions that the coordinates you’re using are (at least locally) flat. We do not account for the curvature of the Earth in very large domains. Hopefully you are using a projected coordinate system (here we are using meters UTM), or at least willing to accept a little distortion. Note that this coord2ind requires units of either meters or decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95aaf432-f377-47ae-aadb-6df938159177",
   "metadata": {},
   "outputs": [],
   "source": [
    "seedinds = pt.coord2ind(seeding_points_loc, (x_min, y_min), np.shape(bathy), grid_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb865fe-1724-4375-9bc6-3c11f4a28f37",
   "metadata": {},
   "source": [
    "The locations might not be in the correct locations. Here we will choose only the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9511ba-d7e4-40c2-a908-f2d1de5082f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_locs = [seedinds[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03936584-17d3-4289-a15c-161d56571cfb",
   "metadata": {},
   "source": [
    "Alternatively, you can select the seeding locations on the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1dcf1d-4aa2-4410-b646-e0fc678f4159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a65c093188474094c1b6d11f01e17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[29.5, -91.3], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c4f76a74154c9382f8445b9faf0448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save Points to Shapefile', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d63f8eeeda45fbb1f5b530466fab0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'google.colab' not in sys.modules:\n",
    "    # Convert model domain polygon to WGS84 to be able to display it on the next map\n",
    "    f_seeding_points = os.path.join(mydir, 'seeding_points.shp')\n",
    "    domain_gdf_4326 = domain_gdf.to_crs(epsg=4326)\n",
    "    domain_polygon_4326 = np.asarray(domain_gdf_4326.geometry[0].boundary.xy).T\n",
    "    anuga_dpt.draw_points_in_polygon(filename=f_seeding_points, epsg=32615, domain_polygon=domain_polygon_4326)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5e9d1-3cad-45ea-a594-5ce53fd6615d",
   "metadata": {},
   "source": [
    "**Note**: If you would like to delete the previous points, you would need to reload the map above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855e8826-c50e-4c6b-aa92-6d562c9846d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "/Users/soloy/Documents/GitHub/deltax_workshop_2024/tutorials/2_SedimentTransport_Dorado/Nourishment_analysis_unsteady/Nourish_t1.0/seeding_points.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: /Users/soloy/Documents/GitHub/deltax_workshop_2024/tutorials/2_SedimentTransport_Dorado/Nourishment_analysis_unsteady/Nourish_t1.0/seeding_points.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle.colab\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# import the file using the gdp package\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     seeding_points_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_seeding_points\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexplode(ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, index_parts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# transform our shape-file into a list\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     seeding_points_loc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([seeding_points_gdf\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mvalues, seeding_points_gdf\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mvalues])\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/anuga_dx/lib/python3.9/site-packages/geopandas/io/file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/anuga_dx/lib/python3.9/site-packages/geopandas/io/file.py:338\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    339\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/anuga_dx/lib/python3.9/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/anuga_dx/lib/python3.9/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/anuga_dx/lib/python3.9/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: /Users/soloy/Documents/GitHub/deltax_workshop_2024/tutorials/2_SedimentTransport_Dorado/Nourishment_analysis_unsteady/Nourish_t1.0/seeding_points.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "if 'google.colab' not in sys.modules:\n",
    "    # import the file using the gdp package\n",
    "    seeding_points_gdf = gpd.read_file(f_seeding_points).explode(ignore_index = True, index_parts=True).drop(columns=['id'])\n",
    "    \n",
    "    # transform our shape-file into a list\n",
    "    seeding_points_loc = np.asarray([seeding_points_gdf.geometry.x.values, seeding_points_gdf.geometry.y.values]).T.tolist()\n",
    "    \n",
    "    # print the locations to inspect\n",
    "    print(seeding_points_loc)\n",
    "    \n",
    "    seedinds = pt.coord2ind(seeding_points_loc, (x_min, y_min), np.shape(bathy), grid_size)\n",
    "    seed_locs = seedinds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a0117-eea8-4969-a771-a53fc22105e8",
   "metadata": {},
   "source": [
    "Let's look at the new grid and the interpolated elevations to verify that everthing worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774cb544-f353-4adf-a4bb-8bd33bb6b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6), dpi=200)\n",
    "plt.imshow(bathy, vmin = -4, vmax = 1)\n",
    "\n",
    "for ii in range(len(seedinds)):\n",
    "    plt.scatter(seedinds[ii][1], seedinds[ii][0], c='tab:orange',\n",
    "                                edgecolors='black', s=50, linewidths=0.5)\n",
    "plt.colorbar(fraction=0.045)\n",
    "plt.title('Gridded Elevation')\n",
    "\n",
    "# save the figure in your output folder\n",
    "plt.savefig(os.path.join(mydir, 'Map_seeding_point.png' ),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50cf5a2-0fc1-4095-88d8-316e75f19443",
   "metadata": {},
   "source": [
    "### Define the Model Parameters\n",
    "\n",
    "Now that we have pre-converted the input data we need, let’s set up the particle routing to be run. We do this using the *particle_track.modelParams()* class, in which we populate the attributes to suit our application. This includes the gridded hydrodynamic outputs from above, the grid size dx, and tuning parameters which influence our random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a98813-bf82-4e66-b723-8d7f2f55c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start populating particle model with settings\n",
    "params = pt.modelParams()\n",
    "\n",
    "# Constants\n",
    "params.dx = grid_size\n",
    "params.theta = theta\n",
    "params.gamma = 0.0\n",
    "params.dry_depth = 0.01\n",
    "params.model = 'Anuga'\n",
    "params.diff_coeff = 0.0\n",
    "params.verbose = False\n",
    "params.topography = bathy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b1a4e-f909-4dd3-ac03-5ad9f3b0f096",
   "metadata": {},
   "source": [
    "The next step is to define the simulation run time. Here, we need to define the time-steps that we will seed our particles and the number of particles per seeding event. Let's inspect the time-steps saved in our ANUGA output. Those are in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31feaf3-928d-4ac2-b0ce-358b29a7fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e63f7-969d-4652-bcdd-f42e4c8ef36c",
   "metadata": {},
   "source": [
    "Now we define our seeding events and total simulation time for *dorado*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d27aa-9368-4fa7-bf74-77ef10d7ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of total run time in output time-steps\n",
    "num_total_steps = 24\n",
    "\n",
    "# number of particles per seeding event\n",
    "Np_per_step = 5\n",
    "\n",
    "# Create vector of target times (3600 is the output interval in ANUGA for this simulation - needs to be updated if output interval changes)\n",
    "target_times = np.arange(0, 3600*(num_total_steps+1), 3600)\n",
    "print(target_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63bf62-e97e-4423-a710-21b6cde7cc52",
   "metadata": {},
   "source": [
    "The next part defines the plotting function for our output and saves it into our output-folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824ccd3-8dcf-444f-9165-c800eee1d375",
   "metadata": {},
   "source": [
    "### Run the *dorado* model using the run_iteration function\n",
    "The below code \n",
    "1) executes myInterp to grid our additional datasets. If unstruct2grid took a while to grid the first dataset, this function will be considerably faster than re-running that process, because it re-uses most of the results of that first function call. This function only requires as input the new unstructured data to be gridded. All of these variables will have the same grid size as the first dataset, and we assume that they have all the same coordinates.\n",
    "2) generates particles to be routed using *particle_track.generate_particles()*. Here we are using the 'exact' method to generate particles. To seed them randomly within a specified region, we could call the 'random' method instead.\n",
    "3) iterates the particles using the *particle_track.run_iteration()* function\n",
    "4) saves figures of each iteration in the output-folder using the *routines.get_state()* function.\n",
    "  \n",
    "**Note:** Because the particles take different travel paths, at any given iteration they are not guaranteed to be synced up in time. We can check this using the routines.get_state() function, which allows us to slice the walk_data dictionary along a given iteration number. This function logically indexes the dict like walk_data[:][:][iteration], except not quite as simple given the indexing rules of a nested list. There exists an equivalent function, get_time_state(), which slices walk_data along a given travel time, in case there is interest in viewing the particles in sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43739e58-8d22-409c-81b4-2be26ccf2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total simulation time is ', time[-1]/60 , ' minutes')\n",
    "\n",
    "# preallocate the walk data array\n",
    "walk_data = None\n",
    "\n",
    "# for-loop over our time-steps\n",
    "for i in list(range(num_total_steps)):\n",
    "    \n",
    "        \n",
    "    # Update flow fields from new time-step\n",
    "    params.depth = myInterp(depth[i])\n",
    "    params.stage = myInterp(stage[i])\n",
    "    params.qx = myInterp(qx[i])\n",
    "    params.qy = myInterp(qy[i])\n",
    "        \n",
    "    # Instantiate particle class with the parameters defined above\n",
    "    particles_anuga = pt.Particles(params)\n",
    "    \n",
    "    # print progress message\n",
    "    print('We are now at minute ', target_times[i]/60)\n",
    "        \n",
    "    # Generate new batch of particles\n",
    "    for ii in range(len(seed_locs)):\n",
    "        particles_anuga.generate_particles(Np_per_step, [seed_locs[ii][0]], [seed_locs[ii][1]], seed_time=i*3600,method='exact', previous_walk_data=walk_data)\n",
    "         \n",
    "    # Run the random walk for this timestep\n",
    "    walk_data = particles_anuga.run_iteration(target_times[i])\n",
    "    \n",
    "    # Generate new plots\n",
    "    dorado_dvt.do_plotting(i, params, walk_data, seed_locs, target_times, filepath=os.path.join(mydir,'output_%s.png' % i))\n",
    "\n",
    "# Save walk data as a text-file in the output-folder\n",
    "fpath = os.path.join(mydir,'walk_data.txt')\n",
    "json.dump(walk_data, open(fpath, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf4958-7b44-47e5-bc1c-1aa4eaad3322",
   "metadata": {},
   "source": [
    "### Model output processing\n",
    "\n",
    "After running the model, we can use some of the post-processing functionality provided by *dorado*. This includes plotting the nourishment area and nourishment time. We can also investigate the flow paths like in the steady simulation from Example 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c9070-34a4-420b-9b7c-5fef94d0ba31",
   "metadata": {},
   "source": [
    "#### Nourishment area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b6441-d9eb-476a-bacb-ced80cecf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the frequency of particles entering each grid cell (relative nourishment)\n",
    "visit_freq = pt.nourishment_area(walk_data, params.topography.shape, sigma=0.8)\n",
    "\n",
    "# plot the map of nourishment using the show_nourishment() function\n",
    "fig = plt.figure(figsize=(5,5), dpi=300)\n",
    "ax = drt.show_nourishment_area(visit_freq, params.topography, walk_data=walk_data, \n",
    "                               cmap='Blues', seed_color='magenta')\n",
    "ax.set_xticks([],[])\n",
    "ax.set_yticks([],[])\n",
    "\n",
    "# set the title and save the figure\n",
    "plt.title('Nourishment Area ($theta$ = %s)' % (theta))\n",
    "plt.savefig(os.path.join(mydir, 'NourishmentArea_t%s.png' % (theta)),\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d1fe5-37c1-4b83-af71-4f04ece16447",
   "metadata": {},
   "source": [
    "The Nourishment Area plot shows regions colored depending on how frequently each cell was occupied by particles. Because we are often interested in where particles can go in general, rather than exactly where they have gone, by default this function will perform a small amount of Gaussian filtering, to smooth out some of the stochasticity in the travel paths. This smoothing can be turned off or ramped up depending on the application. \n",
    "\n",
    "Because the Nourishment Area is a time-integrated measure of where particles are going, we may also want to know how long particles tend to stay there once they get there. For this question, we have provided a second function, which we are calling the Nourishment Time, which computes how long on average particles spend in each cell they travel through. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdd91e-c53f-4d66-b659-0f19ae2a3821",
   "metadata": {},
   "source": [
    "#### Nourishment times\n",
    "\n",
    "We compute nourishment times by calling on the *nourishment_time* function, and visualize the results using the *show_nourishment_time* routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebb2a2-64cd-47f7-a1c6-282cfa48b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close previous figure\n",
    "plt.close()\n",
    "\n",
    "# calculate the time that particles spend in each grid cell (residence time per particle)\n",
    "mean_times = pt.nourishment_time(walk_data, params.depth.shape, clip=95)\n",
    "\n",
    "# plot the map of nourishment time using the show_nourishment_time() function\n",
    "fig = plt.figure(figsize=(5,5), dpi=300)\n",
    "ax = drt.show_nourishment_time(mean_times, params.depth, walk_data)\n",
    "\n",
    "ax.set_xticks([],[])\n",
    "ax.set_yticks([],[])\n",
    "\n",
    "# save the figure\n",
    "plt.savefig(os.path.join(mydir, 'NourishmentTime_t%s.png' % (theta)),\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521ecd8-8393-44a6-90c4-1ce2b21aacbc",
   "metadata": {},
   "source": [
    "#### Plot travel paths in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9211666-d668-42bb-a741-d7abb87746c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close previous figure\n",
    "plt.close()\n",
    "\n",
    "# plot the travel path by giving the ID of each particle\n",
    "if 'google.colab' not in sys.modules:\n",
    "    drt.draw_travel_path(params.depth, walk_data, np.arange(0,10), os.path.join(mydir, 'Travel_paths_t%s.png' % (theta)),interval=2, plot_legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d1357-870d-4dd4-8d3a-a1c0621d21e7",
   "metadata": {},
   "source": [
    "#### Assess exposure time of an area to particles\n",
    "\n",
    "For something a little more interesting, let’s measure the amount of time particles spent “exposed” to a specific sub-region within our domain. For this we make use of the functions particle_track.exposure_time() and routines.plot_exposure_time(). If we input a binary array (same size as input arrays) delineating our region of interest (ROI) with 1’s, these functions will compute and plot the exposure time distribution (ETD) of particles in this sub-region.\n",
    "\n",
    "For those familiar with the metric, the ETD is equivalent to the residence time distribution (RTD) for steady flows, with the only difference being that if particles make multiple excursions into our ROI, all those times are counted.\n",
    "\n",
    "Note: For a representative ETD, it is important to run a lot of particles. A large sample size is needed to obtain a realistic distribution (and smooth plots). Depending on the domain, we recommend at least O($10^3$)\n",
    "\n",
    "Here we are interested in the distribution of how often particles enter the wetlands at elevations above 0 m. Alternatively, one could have defined the roi also based on the friction classification or mean water levels. First, let’s generate and visualize the ROI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c170b6-7fee-43eb-9d11-ed9b1431fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define region of interest\n",
    "roi =  np.ones(params.topography.shape)\n",
    "\n",
    "# define a threshold to extract area of interest (here we look at elevations above 0 m)\n",
    "roi[params.topography<0] = 0\n",
    "\n",
    "# plot the roi\n",
    "plt.figure(figsize=(6,6), dpi=200)\n",
    "plt.imshow(bathy, vmin = -4, vmax = 1)\n",
    "plt.contour(np.arange(roi.shape[1]),np.arange(roi.shape[0]),roi, colors = 'black',linewidths = 0.1)\n",
    "for ii in range(len(seed_locs)):\n",
    "    plt.scatter(seed_locs[ii][1], seed_locs[ii][0], c='tab:orange',\n",
    "                                edgecolors='black', s=20, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5a26a-70cb-45cb-bd43-011e78f7d887",
   "metadata": {},
   "source": [
    "Then compute. exposure_time() outputs a list of exposure times by particle index, and plot_exposure_time() will use those values to generate plots of the cumulative and differential forms of the ETD (i.e. the CDF and PDF, respectively).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc67a16-589c-4010-abaf-d1ebff14ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure exposure times\n",
    "exposure_times = pt.exposure_time(walk_data, roi, verbose=True)\n",
    "\n",
    "print(exposure_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61718d2d-c160-433d-a39d-8e031fec7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then generate plots and save data\n",
    "exposure_times = drt.plot_exposure_time(walk_data,\n",
    "                                                    exposure_times,\n",
    "                                                    os.path.join(mydir, 'exposure_times%s.png' % (theta)),\n",
    "                                                    timedelta = 3600, nbins=20)\n",
    "# Changing 'timedelta' will change the units of the time-axis.\n",
    "# Units are seconds, so 60 will plot by minute.\n",
    "# Because we are using fewer particles than ideal, smooth the plots with small 'nbins'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b66abc-b344-404a-952a-31d4ac3251a1",
   "metadata": {},
   "source": [
    "**Note**: If any particles are still in the ROI at the end of their travel history, they are excluded from plots. These particles are not done being “exposed,” so we need to run more iterations in order to capture the tail of the distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
